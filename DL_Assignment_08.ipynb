{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzC+yDezPuiuH9Izsl5/jP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshkumar145/DL_Theory/blob/main/DL_Assignment_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tWhat are the pros and cons of using a stateful RNN versus a stateless RNN?**\n",
        "\n",
        "**Ans:** \n",
        "\n",
        "**STATEFUL**\n",
        "\n",
        "**Advantages of Stateful :**\n",
        "\n",
        "* Stateful protocols are well known for their state of connection. \n",
        "*  his protocol comes up with a healthier performance for the end-user by maintaining the detailed track of the connection and since it keeps the track, it comes up with superior performance. \n",
        "* The requests usually made from these protocols are generally depending on the server-side state. \n",
        "* The applications of Stateful protocol need some backup storage. \n",
        "\n",
        "**Disadvantages of Stateful :**\n",
        "\n",
        "* As we know this protocol highly relies on backup storage, which could cause a reduction in performance. \n",
        "* Also, these protocols are greatly reliant on the server-side. \n",
        "* This protocol needs memory allotment as a dependent to reserve the data. \n",
        "* Also, we know that Stateful protocols are extremely dependent on the server-side states. \n",
        "\n",
        "**STATELESS**\n",
        "\n",
        "**Advantages of Stateless Protocol**\n",
        "* Stateless protocols enhance visibility as every request is its own resource and can be treated. \n",
        "* It allows stability across different other applications. \n",
        "* In this protocol, every single communication is disconnected and unique from the ones that are made after or before it.  \n",
        "* An application seems to be more comfortable to work with and more supportable when using Stateless protocol. In Stateless protocol, there is no need to reference data to another packet, every packet of data/ information proceeds on its own. \n",
        "* New occurrences of an application can be included or deleted on request. \n",
        "* Stateless protocols also eliminate the overhead to create or use the sessions.\n",
        "\n",
        "**Disadvantages of Stateless Protocol**\n",
        "* The limitation of Stateless protocol is that they do not hold back data about a specific user session. \n",
        "* They are also intrinsically not as capable, as they do not reserve data about a certain end-user session. This could result in tiresome for the end-user as they do not have specific sessions where the information is not stored. \n",
        "* For Stateless application, it may be necessary to take in supplementary data in every demand and correspondingly the outcome would be that the server will be in need to explain this up-to-date information. \n",
        "* As Stateless Protocols do not reserve any data, they might degrade network processes with the growth of repetitive details."
      ],
      "metadata": {
        "id": "HjA389uwBwqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.\tWhy do people use Encoder–Decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?** \n",
        "\n",
        "**Ans:** \n",
        "Encoder–Decoder RNNs are the ability to train a single end-to-end model directly on source and target sentences and the ability to handle variable length input and output sequences of text."
      ],
      "metadata": {
        "id": "EBw9uS17BujE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tHow can you deal with variable-length input sequences? What about variable-length output sequences?**\n",
        "\n",
        "**Ans:**\n",
        "In the case of variable length sequence prediction problems, this requires that your data be transformed such that each sequence has the same length.This vectorization allows code to efficiently perform the matrix operations in batch for your chosen deep learning algorithms.\n",
        "\n",
        "The most common way people deal with inputs of varying length is padding.You first define the desired sequence length, i.e. the input length you want your model to have. Then any sequences with a shorter length than this are padded either with zeros or with special characters so that they reach the desired length."
      ],
      "metadata": {
        "id": "3SB1ZtRtBtIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.\tWhat is beam search and why would you use it? What tool can you use to implement it?**\n",
        "\n",
        "**Ans:** Beam search is an algorithm used in many NLP and speech recognition models as a final decision making layer to choose the best output given target variables like maximum probability or next output character.A beam search is most often used to maintain tractability in large systems with insufficient amount of memory to store the entire search tree."
      ],
      "metadata": {
        "id": "ZIE9vtLABrq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.\tWhat is an attention mechanism? How does it help?**\n",
        "\n",
        "**Ans:** Attention Mechanism is also an attempt to implement the same action of selectively concentrating on a few relevant things, while ignoring others in deep neural networks. The idea behind the attention mechanism was to permit the decoder to utilize the most relevant parts of the input sequence in a flexible manner, by a weighted combination of all the encoded input vectors, with the most relevant vectors being attributed the highest weights."
      ],
      "metadata": {
        "id": "ldTg9X0VBqPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.\tWhat is the most important layer in the Transformer architecture? What is its purpose?** \n",
        "\n",
        "**Ans:** The most important part here is the “Residual Connections” around the layers. This is very important in retaining the position related information which we are adding to the input representation/embedding across the network. The network displayed catastrophic results on removing the Residual Connections."
      ],
      "metadata": {
        "id": "9bUZwlS6Bo_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.\tWhen would you need to use sampled softmax?**\n",
        "\n",
        "**Ans:** Sampled softmax aims to approximate a full softmax during model training. Rather than computing the loss over all classes, only the positive class and a sample of m negative classes are considered. Each negative class is sampled with probability qi with replacement."
      ],
      "metadata": {
        "id": "ieIUU1OjBlgs"
      }
    }
  ]
}